"""
Topic Prompts - System prompts and JSON schemas for topic selection.
"""
from typing import List, Dict, Any


def get_topic_selection_system_prompt() -> str:
    """Get system prompt for topic selection submitter."""
    return """You are an autonomous mathematical research agent selecting the next research avenue to explore. Your role is to:

1. Review the user's high-level research goal
2. Review all existing brainstorm topics and their status
3. Review all completed papers (titles, abstracts, word counts)
4. Decide the best next action: start a new topic, continue an existing topic, or combine topics

⚠️ CRITICAL - INTERNAL CONTENT WARNING ⚠️

ALL context provided to you (brainstorm databases, accepted submissions, papers, reference materials, outlines, previous document content) is AI-GENERATED within this research system. This content has NOT been peer-reviewed, published, or verified by external sources.

YOU MUST TREAT ALL PROVIDED CONTEXT WITH EXTREME SKEPTICISM:
- NEVER assume claims are true because they "sound good" or "fit well"
- NEVER trust information simply because it appears in "accepted submissions" or "papers"
- ALWAYS verify information independently before using or building upon it
- NEVER cite internal documents as authoritative or established sources
- Question and validate every assertion, even if it appears in validated content

WEB SEARCH STRONGLY ENCOURAGED:
If your model has access to real-time web search capabilities (such as Perplexity Sonar or similar), you are STRONGLY ENCOURAGED to use them to:
- Verify mathematical claims against current published research
- Access recent developments and contemporary mathematical literature
- Cross-reference theorems, proofs, and techniques with authoritative sources
- Supplement analysis with verified external information
- Validate approaches against established mathematical consensus

The internal context shows what has been explored by AI agents, NOT what has been proven correct. Your role is to generate rigorous, verifiable mathematical content. Use all available resources - internal context as exploration history, your base knowledge for reasoning, and web search (if available) for verification and current information.

WHEN IN DOUBT: Verify independently. Do not assume. Do not trust unverified internal context as truth. If you have web search, use it.

---

YOUR TASK:
Select the optimal research avenue that best advances the user's research goal.

DECISION OPTIONS:
1. NEW_TOPIC - Create a brand new brainstorm topic to explore
2. CONTINUE_EXISTING - Resume work on an incomplete brainstorm that has more value to explore
3. COMBINE_TOPICS - Merge multiple related brainstorms into a unified exploration

DECISION CRITERIA:

When to choose NEW_TOPIC:
- All existing topics are complete OR
- A genuinely new mathematical avenue would provide more research value than continuing existing work
- The new topic addresses an unexplored area relevant to the research goal
- Existing papers don't adequately cover this mathematical territory

When to choose CONTINUE_EXISTING:
- An incomplete brainstorm has significant untapped mathematical depth
- The brainstorm has few submissions relative to its mathematical richness
- Continuing would yield more valuable insights than starting fresh

When to choose COMBINE_TOPICS:
- Multiple existing brainstorms are deeply interconnected
- A unified exploration would reveal insights neither topic could provide alone
- The mathematical concepts naturally bridge multiple brainstorms

CRITICAL REQUIREMENTS:
- Focus on mathematical rigor and logical soundness
- Avoid redundancy with existing work
- Ensure topic selection serves the user's research goal
- Consider the existing paper library to avoid redundant explorations

CRITICAL JSON ESCAPE RULES:
1. Backslashes: ALWAYS use double backslash (\\\\) for any backslash in your text
   - Example: Write "\\\\tau" not "\\tau", write "\\\\(" not "\\("
2. Quotes: Escape double quotes inside strings as \\"
3. Newlines/Tabs: Use \\n for newlines (NOT \\\\n), \\t for tabs (NOT \\\\t)
4. LaTeX notation: If your content contains mathematical expressions like \\Delta, \\tau, etc.,
   you MUST escape the backslash: write "\\\\Delta", "\\\\tau", "\\\\[", "\\\\]"

Output your decision ONLY as JSON in the required format."""


def get_topic_selection_json_schema() -> str:
    """Get JSON schema for topic selection."""
    return """REQUIRED JSON FORMAT:
{
  "action": "new_topic | continue_existing | combine_topics",
  "topic_id": "string - Required if action is continue_existing (e.g., 'topic_003')",
  "topic_ids": ["array of topic_ids - Required if action is combine_topics (e.g., ['topic_001', 'topic_002'])"],
  "topic_prompt": "string - Required if action is new_topic or combine_topics. The brainstorm question/avenue to explore",
  "reasoning": "string - Why this is the best choice right now"
}

FIELD REQUIREMENTS:
- action: MUST be one of: "new_topic", "continue_existing", "combine_topics"
- topic_id: Required ONLY if action is "continue_existing"
- topic_ids: Required ONLY if action is "combine_topics" (array of 2+ topic IDs)
- topic_prompt: Required if action is "new_topic" OR "combine_topics"
- reasoning: ALWAYS required

EXAMPLES:

New Topic:
{
  "action": "new_topic",
  "topic_prompt": "Explore connections between modular forms and Galois representations in the context of the Langlands program",
  "reasoning": "The existing brainstorms have covered L-functions and automorphic representations. Modular forms provide a concrete computational entry point to the Langlands correspondence that hasn't been explored yet."
}

Continue Existing:
{
  "action": "continue_existing",
  "topic_id": "topic_003",
  "reasoning": "The brainstorm on reciprocity laws has only 7 submissions and has not yet covered explicit formulas or computational approaches. Continuing this topic will provide more complete understanding before moving to a new avenue."
}

Combine Topics:
{
  "action": "combine_topics",
  "topic_ids": ["topic_002", "topic_005"],
  "topic_prompt": "Unified exploration of local and global class field theory with applications to the Langlands program",
  "reasoning": "Topics 002 (local class field theory) and 005 (global reciprocity) are closely related and would benefit from unified treatment. Combining them will reveal deeper connections."
}"""


def get_topic_validator_system_prompt() -> str:
    """Get system prompt for topic validator."""
    return """You are validating a topic selection decision in an autonomous mathematical research system. Your role is to:

1. Review the user's high-level research goal
2. Review all existing brainstorm topics and their status
3. Review all completed papers (titles, abstracts, word counts)
4. Evaluate whether the proposed topic selection is optimal

⚠️ CRITICAL - INTERNAL CONTENT WARNING ⚠️

ALL context provided to you (brainstorm databases, accepted submissions, papers, reference materials, outlines, previous document content) is AI-GENERATED within this research system. This content has NOT been peer-reviewed, published, or verified by external sources.

YOU MUST TREAT ALL PROVIDED CONTEXT WITH EXTREME SKEPTICISM:
- NEVER assume claims are true because they "sound good" or "fit well"
- NEVER trust information simply because it appears in "accepted submissions" or "papers"
- ALWAYS verify information independently before using or building upon it
- NEVER cite internal documents as authoritative or established sources
- Question and validate every assertion, even if it appears in validated content

WEB SEARCH STRONGLY ENCOURAGED:
If your model has access to real-time web search capabilities (such as Perplexity Sonar or similar), you are STRONGLY ENCOURAGED to use them to:
- Verify mathematical claims against current published research
- Access recent developments and contemporary mathematical literature
- Cross-reference theorems, proofs, and techniques with authoritative sources
- Supplement analysis with verified external information
- Validate approaches against established mathematical consensus

The internal context shows what has been explored by AI agents, NOT what has been proven correct. Your role is to generate rigorous, verifiable mathematical content. Use all available resources - internal context as exploration history, your base knowledge for reasoning, and web search (if available) for verification and current information.

WHEN IN DOUBT: Verify independently. Do not assume. Do not trust unverified internal context as truth. If you have web search, use it.

---

YOUR TASK:
Validate whether the proposed topic selection represents the best use of research resources.

VALIDATION CRITERIA:

ACCEPT the topic selection if:
1. NEW_TOPIC: The new topic addresses a genuinely valuable mathematical avenue not yet covered
2. CONTINUE_EXISTING: The brainstorm's current state justifies continuation (incomplete, mathematically rich)
3. COMBINE_TOPICS: There are clear mathematical connections that justify unification
4. The choice is relevant to the user's research goal
5. The reasoning is sound and mathematically grounded
6. The topic doesn't duplicate existing completed work

REJECT the topic selection if:
1. NEW_TOPIC: The topic duplicates an existing brainstorm or completed paper
2. CONTINUE_EXISTING: The brainstorm should be marked complete (exhausted) or a new topic would be more valuable
3. COMBINE_TOPICS: The topics lack clear mathematical connections for unification
4. The choice ignores more valuable research avenues
5. The reasoning is flawed or lacks mathematical rigor
6. The selection would lead to redundant work

REJECTION FEEDBACK FORMAT:
If rejecting, provide CONCRETE, ACTIONABLE guidance:

"REJECTION REASON: [Duplicate Topic|Should Complete|Weak Connections|Ignores Better Avenue|etc.]

ISSUE: [What's wrong with the proposed selection]

BETTER ALTERNATIVE: [What would be a more optimal choice]

EXAMPLE: [Concrete example of a good topic selection given current state]"

CRITICAL JSON ESCAPE RULES:
1. Backslashes: ALWAYS use double backslash (\\\\) for any backslash in your text
2. Quotes: Escape double quotes inside strings as \\"
3. Newlines/Tabs: Use \\n for newlines, \\t for tabs

Output your decision ONLY as JSON in the required format."""


def get_topic_validator_json_schema() -> str:
    """Get JSON schema for topic validator."""
    return """REQUIRED JSON FORMAT:
{
  "decision": "accept | reject",
  "reasoning": "string - Detailed explanation for the decision"
}

FIELD REQUIREMENTS:
- decision: MUST be either "accept" or "reject"
- reasoning: ALWAYS required - detailed explanation (use structured format below if rejecting)

EXAMPLE (Accept):
{
  "decision": "accept",
  "reasoning": "The proposed topic on modular forms represents a valuable new avenue that complements existing brainstorms on L-functions. The submitter correctly identifies this as a concrete entry point to Langlands correspondence that hasn't been explored in prior topics."
}

EXAMPLE (Reject - Use Structured Format):
{
  "decision": "reject",
  "reasoning": "REJECTION REASON: Duplicate Topic\n\nISSUE: The proposed new topic on 'Galois representations' duplicates existing brainstorm topic_005 which already explores this area.\n\nBETTER ALTERNATIVE: Either continue topic_005 (which has only 8 submissions) or explore a related but distinct area such as 'Applications of Galois representations to arithmetic geometry'.\n\nEXAMPLE: action='continue_existing', topic_id='topic_005'"
}"""


def build_topic_selection_prompt(
    user_research_prompt: str,
    brainstorms_summary: List[Dict[str, Any]],
    papers_summary: List[Dict[str, Any]],
    rejection_context: str = ""
) -> str:
    """
    Build the complete topic selection prompt with context.
    
    Args:
        user_research_prompt: The user's high-level research goal
        brainstorms_summary: List of all brainstorms with metadata
        papers_summary: List of all papers with title, abstract, word count
        rejection_context: Formatted previous rejection feedback
    
    Returns:
        Complete prompt string
    """
    parts = [
        get_topic_selection_system_prompt(),
        "\n---\n",
        get_topic_selection_json_schema(),
        "\n---\n",
        f"USER RESEARCH GOAL:\n{user_research_prompt}",
        "\n---\n"
    ]
    
    # Add brainstorms summary
    if brainstorms_summary:
        parts.append("EXISTING BRAINSTORM TOPICS:\n")
        for b in brainstorms_summary:
            parts.append(f"\n- Topic ID: {b.get('topic_id', 'Unknown')}")
            parts.append(f"  Prompt: {b.get('topic_prompt', 'N/A')}")
            parts.append(f"  Status: {b.get('status', 'Unknown')}")
            parts.append(f"  Submissions: {b.get('submission_count', 0)}")
            papers = b.get('papers_generated', [])
            if papers:
                parts.append(f"  Papers Generated: {', '.join(papers)}")
        parts.append("\n---\n")
    else:
        parts.append("EXISTING BRAINSTORM TOPICS: None yet\n---\n")
    
    # Add papers summary
    if papers_summary:
        parts.append("COMPLETED PAPERS (Tier 2):\n")
        for p in papers_summary:
            parts.append(f"\n- Paper ID: {p.get('paper_id', 'Unknown')}")
            parts.append(f"  Title: {p.get('title', 'N/A')}")
            parts.append(f"  Abstract: {p.get('abstract', 'N/A')}")
            parts.append(f"  Word Count: {p.get('word_count', 0)}")
            source_ids = p.get('source_brainstorm_ids', [])
            if source_ids:
                parts.append(f"  Source Brainstorms: {', '.join(source_ids)}")
        parts.append("\n---\n")
    else:
        parts.append("COMPLETED PAPERS: None yet\n---\n")
    
    # Add rejection context if any
    if rejection_context:
        parts.append(f"{rejection_context}\n---\n")
    
    parts.append("Now select the next topic and provide your decision as JSON:")
    
    return "".join(parts)


def build_topic_validation_prompt(
    user_research_prompt: str,
    brainstorms_summary: List[Dict[str, Any]],
    papers_summary: List[Dict[str, Any]],
    proposed_action: Dict[str, Any]
) -> str:
    """
    Build the complete topic validation prompt with context.
    
    Args:
        user_research_prompt: The user's high-level research goal
        brainstorms_summary: List of all brainstorms with metadata
        papers_summary: List of all papers with title, abstract, word count
        proposed_action: The topic selection submission to validate
    
    Returns:
        Complete prompt string
    """
    parts = [
        get_topic_validator_system_prompt(),
        "\n---\n",
        get_topic_validator_json_schema(),
        "\n---\n",
        f"USER RESEARCH GOAL:\n{user_research_prompt}",
        "\n---\n"
    ]
    
    # Add brainstorms summary
    if brainstorms_summary:
        parts.append("EXISTING BRAINSTORM TOPICS:\n")
        for b in brainstorms_summary:
            parts.append(f"\n- Topic ID: {b.get('topic_id', 'Unknown')}")
            parts.append(f"  Prompt: {b.get('topic_prompt', 'N/A')}")
            parts.append(f"  Status: {b.get('status', 'Unknown')}")
            parts.append(f"  Submissions: {b.get('submission_count', 0)}")
        parts.append("\n---\n")
    else:
        parts.append("EXISTING BRAINSTORM TOPICS: None yet\n---\n")
    
    # Add papers summary
    if papers_summary:
        parts.append("COMPLETED PAPERS (Tier 2):\n")
        for p in papers_summary:
            parts.append(f"\n- Paper ID: {p.get('paper_id', 'Unknown')}")
            parts.append(f"  Title: {p.get('title', 'N/A')}")
            parts.append(f"  Abstract: {p.get('abstract', 'N/A')[:500]}...")
            parts.append(f"  Word Count: {p.get('word_count', 0)}")
        parts.append("\n---\n")
    else:
        parts.append("COMPLETED PAPERS: None yet\n---\n")
    
    # Add proposed action
    parts.append("PROPOSED TOPIC SELECTION:\n")
    parts.append(f"Action: {proposed_action.get('action', 'Unknown')}")
    if proposed_action.get('topic_id'):
        parts.append(f"\nTopic ID: {proposed_action.get('topic_id')}")
    if proposed_action.get('topic_ids'):
        parts.append(f"\nTopic IDs to Combine: {', '.join(proposed_action.get('topic_ids', []))}")
    if proposed_action.get('topic_prompt'):
        parts.append(f"\nTopic Prompt: {proposed_action.get('topic_prompt')}")
    parts.append(f"\nReasoning: {proposed_action.get('reasoning', 'N/A')}")
    
    parts.append("\n---\n")
    parts.append("Validate this topic selection and provide your decision as JSON:")
    
    return "".join(parts)

